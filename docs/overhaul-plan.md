# RulesForMe 重构规划与最佳实践指南

## 背景
- 项目最初作为个人化的 Clash/Surge 规则聚合器，逐步叠加了下载、去重、统计、通知等功能，但演进过程中缺少系统化设计。
- 目前仓库混合了 Bash、Python、JS 与手工维护的规则文件，既有自动拉取也有手工复制，导致行为不可预测、维护成本高。
- 在进行任何进一步开发或大规模调整之前，需要先明确目标状态与渐进式落地方案，以避免再次失控。

## 当前主要问题快照
- `scripts/update_rules.sh:1`：>100 行逐条 `curl`，没有配置化、缺少重试/校验、与 Python 合并脚本逻辑分割严重，极难维护。
- `scripts/consolidate_rules.py:1`：核心逻辑集中在单文件，职责耦合（下载、解析、过滤、统计、通知），缺少类型标注/单元测试；部分注释掉的来源仍被 README 描述。
- `README.md:1`：对功能的描述（CRUD、全量直连/拒绝列表等）与当前实现脱节，容易误导贡献者或用户。
- `rule_stats.json:1`：统计中保留了已弃用分类（如 `privacy_all`、`BlockHttpDNS`），数值与 `RULE_CATEGORIES` 不一致，缺乏生成机制说明。
- `.github/workflows/update-rules.yml:1`：无依赖缓存、没有显式的运行日志或工件存档，错误诊断困难；脚本失败时缺乏报警机制。
- 代码库没有依赖锁定、缺少 lint/format/test 约束，也没有明确的贡献指南或发布流程。

## 改进目标
- 打造数据驱动、配置化的规则采集与合并流水线，最小化硬编码。
- 建立可测试、可观测、可回滚的自动化体系，保障每日 GitHub Actions 运行稳定。
- 明确文档、代码、配置、产物之间的契约关系，降低单点知识风险。
- 为后续模块化扩展（更多规则源、不同输出格式）打好架构基础。

## 分阶段路线图
1. **Phase 0 — 基线梳理**：锁定现有规则来源、输出格式、部署目标；补齐文档（本文档即成果之一）。
2. **Phase 1 — 配置与数据层重构**：引入统一的规则源清单、输出映射和元数据验证。
3. **Phase 2 — 核心脚本模块化**：将获取、解析、合并、统计、通知拆分为可测试的 Python 模块，替换或吸收 Bash 脚本职责。
4. **Phase 3 — 质量保障体系**：补齐单元测试、端到端测试、静态检查、依赖锁定，完善 CI/CD。
5. **Phase 4 — 文档与运维**：更新 README/贡献指南，记录运维手册（监控、回滚、手工干预流程），视情况发布版本标签。

## 重点任务详解
### 配置与数据源管理
- 新建 `rulesources.yaml`（或 `ruleset_manifest.yaml`），以结构化方式描述每个分类：
  - 源列表（支持本地相对路径与远程 URL）。
  - 源类型（list/yaml/json/mrs 等）及解析策略。
  - 输出目标（文件名、格式、是否合并）。
  - 后处理策略（去重、关键字白名单/黑名单、排序方式）。
- 对 manifest 做 JSON Schema 校验，CI 中跑 `python -m jsonschema` 或 `pydantic` 验证，杜绝手误引发的运行时错误。
- 为远程源补充元数据：更新频率、期望行数区间、可用性标签；结合这类信息决定超时、重试与容灾策略。

### Python 代码体系
- 将现有脚本迁移到 `src/rulesforme/` 包，拆分成模块：`config.py`、`fetch.py`、`parser.py`、`merger.py`、`stats.py`、`notify.py`、`cli.py`。
- 引入 `pyproject.toml`（首选 `uv`/`poetry`/`pip-tools` 管理依赖），同时生成 `requirements.lock` 以便 GitHub Actions 与本地保持一致。
- 全面添加类型标注与 `mypy` 检查；使用 `dataclasses`/`pydantic` 表达配置结构，减少动态字典访问。
- 将白名单、忽略规则、正则等策略外置到配置/数据层，避免散落在代码里。
- 提供 `--dry-run`、`--diff`、`--category` 等 CLI 选项，便于调试与灰度发布。

### 采集流程与 Bash 脚本
- 用 Python 采集模块替换 `scripts/update_rules.sh`，通过 manifest 遍历所有源。
- 实现统一的下载器：
  - 支持并发（`asyncio`/`httpx` 或 `concurrent.futures`），以及串行回退。
  - 对于大文件启用流式写入、计算 SHA256、记录文件大小以供审计。
  - 失败时区分“可忽略”与“致命”类型（manifest 中声明），并输出结构化日志。
- 将下载结果缓存到 `data/cache/`，使用 `ETag`/`Last-Modified` 或哈希命名，配合过期策略减少无谓重复下载。

### 规则合并与输出
- 为不同输出类型定义标准接口：`RuleSet` 基类 + `ListRuleSet`、`YamlRuleSet` 等，实现统一合并/去重逻辑。
- 统一输出命名与目录结构，显式标注生成物与手工维护物（可通过 `.generated` 标记或 README 说明）。
- 对统计文件改写为自动派生（不要人工编辑），字段包含新增/移除数量、源健康状态，并生成变更摘要供通知使用。

### 测试与质量保障
- 引入 `pytest`，针对解析器、合并器、白名单逻辑编写单元测试，使用 `tests/fixtures/` 存放精简样例。
- 通过 `pytest-httpx` 或 `responses` 模拟远程源，验证错误路径与重试策略。
- 建立 `pre-commit` 链条：`ruff`（lint/format）、`mypy`、`pyproject-fmt` 等，保证提交前质量。
- 对生成物提供轻量的端到端校验脚本：检查文件存在、行数/哈希在安全区间。

### 自动化与运维
- 优化 GitHub Actions：
  - 使用 `actions/setup-python` + `uv`/`pip-tools` 缓存依赖。
  - 拆分步骤：下载 → 合并 → 验证 → 生成报告（上传日志/差异为 Artifact）。
  - 若检测到关键源失败，向 Bark 或其他渠道发送告警，并在 GitHub Action 中标记 warning。
- 记录执行日志（JSON 或 markdown 报告）便于追溯；必要时保留最近 N 次生成物归档。
- 设计回滚策略：例如通过 `git tag` + `gh release` 保存稳定版本，出问题时替换引用地址。

### 文档与协作
- 重写 `README.md`，聚焦实际能力、快速开始、常见用例、限制说明。
- 新增 `CONTRIBUTING.md`：
  - 如何运行测试、格式化代码。
  - 如何添加新的规则源（manifest 规范、测试要求）。
- 撰写运维手册：
  - 失败排查（日志位置、常见 HTTP 错误、手动触发 Action）。
  - 本地调试步骤、所需环境变量（如 `BARK_URL`）。
- 视后续需求，补充多语言文档或将中文/英文版拆分管理。

## 测试策略草案
- **单元测试**：解析函数、白名单过滤、统计更新等纯函数逻辑。
- **组件测试**：对 manifest 中单个分类执行下载模拟 + 合并，校验输出结果与统计信息。
- **端到端测试**：在 CI 中对少量来源执行真实请求（可选择公共稳定源），其余通过 Mock，确保流程可执行。
- **静态检查**：`ruff check`、`ruff format`、`mypy`, `pip-audit` 或 `uv pip check`。
- **性能监控**：记录下载时间、合并时间及最终产物规模，作为回归判断基线。

## 风险与待确认问题
- 某些来源（例如 `rulesets/custom/*.list`）是否必须与上游仓库保持同步，还是允许完全由本仓库维护？
- 对于体量巨大的广告/隐私列表，是否要继续整合，还是改为提供可选模块？
- Bark 是否是唯一通知通道，是否需要支持替代（Telegram Bot、Webhook 等）？
- 生成产物当前主要服务于哪些客户端（Clash、Surge、Mihomo 等），是否需要针对不同客户端输出多份格式？
- 对旧有分类（`privacy_all` 等）是计划恢复还是正式废弃？需在 manifest 与 README 中明确。

## 即刻后续动作
1. 与仓库维护者确认上述规划及开放问题，若需调整在文档中迭代。
2. 冻结现有生产流程，仅修复阻塞性问题，避免在未完成重构前继续堆叠。
3. 根据 Phase 1 目标准备配置清单与 Schema，作为下一步编码工作的输入。

> 本文档将作为后续重构任务的约束与验收依据，建议在 PR 中引用并逐项对照执行进度。
